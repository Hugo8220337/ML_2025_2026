\section{Engenharia de Atributos (Feature Engineering)}

\subsection{Visão Geral da Estratégia}

Para a realização deste trabalho montou-se um modelo para deteção de notícias falsas, no entanto, para conseguir um dataset para treinar este modelo, foi necessário enriquecer o dataset, e, para isso foi necessário treinar um conjunto de modelos, cada um especializado numa tarefa diferente, treinados com datasets diferentes, de modo a produzir um modelo final que pudesse prever uma notícia falsa de forma eficaz.

Logo, no trabalho realizado foram treinados os seguintes modelos:

\begin{itemize}
	\item Modelo para deteção de clickbait
	\item Modelo de classificação de tópico
	\item Modelo para análise de contexto
	\item Modelo de análise semântica
	\item Modelo para análise de fake news
\end{itemize}

Esta secção descreve todo o processo de engenharia de atributos para cada um dos datasets utilizados para a construção do modelo final. 

% ----------------------------------------------

\subsection{Pré-processamento e Limpeza de Dados}

\subsubsection{Limpeza de Ruído}
[Remoção de URLs, tags HTML, caracteres especiais e emojis.]

\subsubsection{Normalização de Texto}
[Conversão para minúsculas (lowercase), remoção de acentuação.]

\subsubsection{Tratamento de Stopwords}
[Lista de palavras removidas e justificativa.]

\subsubsection{Lematização e Stemming}
[Técnica escolhida para reduzir as palavras à sua raiz.]

% ----------------------------------------------

\subsection{Extração de Features Linguísticas e Estilísticas}
Nota: Fake news tendem a usar linguagem mais agressiva, erros e excesso de formatação.

\subsubsection{Complexidade Lexical}
[Contagem de palavras, tamanho médio das frases, diversidade de vocabulário.]

\subsubsection{Padrões de Pontuação e Formatação}
[Frequência de letras maiúsculas (ALL CAPS), uso excessivo de pontos de exclamação (!!!).]

\subsubsection{Análise de Erros Gramaticais}
[Se aplicável, uso de ferramentas para contar erros de sintaxe.]

% ------------------------------------------------

\subsection{Extração de Features Semânticas (NLP)}

\subsubsection{Análise de Sentimento e Subjetividade}
[Extração de polaridade (positivo/negativo) e subjetividade (fato vs. opinião).]

\subsubsection{Vetorização de Texto (Representação Numérica)}
Opção A: Bag of Words (BoW) ou N-Grams.

Opção B: TF-IDF (Term Frequency-Inverse Document Frequency).

Opção C: Word Embeddings (Word2Vec, GloVe ou BERT) – especifique qual usou.

% -------------------------------------------------

\subsection{Extração de Features de Contexto e Metadados (Pode não ser aplicável)}

\subsubsection{Análise da Fonte / URL}
[Idade do domínio, presença em listas negras, TLD (.com vs .xyz).]

\subsubsection{Informações Temporais}
[Data da publicação vs. Data do evento relatado.]

\subsubsection{Propagação Social}
[Número de partilhas, likes ou comentários (se o dataset tiver).]

% ----------------------------------------------

\subsection{Seleção e Otimização de Features}

\subsubsection{Análise de Correlação}
[Matriz de correlação para remover variáveis redundantes.]

\subsubsection{Redução de Dimensionalidade}
[Uso de PCA (Principal Component Analysis) ou SVD, se houver muitos dados.]

\subsubsection{Ranking de Importância}
[Métodos estatísticos (Chi-quadrado, ANOVA) ou baseados em modelos (Feature Importance de Random Forest) para escolher as melhores.]

% ---------------------------------------------

\subsection{Matriz de Features Final}
[Resumo final: Quantas colunas/variáveis restaram para entrar no modelo de treino e descrição do formato final dos dados (X\_train).]

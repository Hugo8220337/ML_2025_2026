\section{Desenvolvimento dos Modelos (Metodologia)} \label{sec:desenvolvimento-modelos}
% Aqui descreves o "coração" do trabalho. Para cada sub-tópico abaixo, deves identificar e justificar os algoritmos e parâmetros.

O presente capítulo detalha a metodologia adotada para o desenvolvimento do sistema de deteção de \textit{Fake News}. Dada a natureza multidimensional da desinformação, optou-se por uma arquitetura modular hierárquica (abordagem inspirada em \textit{Stacking Ensemble}), em vez de um único modelo monolítico.

Para tal, foram desenvolvidos modelos especialistas independentes, treinados em \textit{datasets} distintos, cujo objetivo é capturar diferentes nuances linguísticas e estruturais das notícias. As saídas probabilísticas destes modelos funcionam como \textit{features} de alto nível (meta-features) para o classificador final.

A arquitetura proposta compreende os seguintes módulos:

\begin{itemize}
	\item \textbf{Classificação de Tópicos:} Contextualização temática do artigo (ex: Política, Saúde, Tecnologia);
	\item \textbf{Análise de Anomalias:} Identificação de padrões nos textuais em notícias verdadeiras de modo a detetar anomalias;
	\item \textbf{Deteção de Stance (Postura):} Análise da concordância entre o título e o corpo da notícia;
	\item \textbf{Deteção de Clickbait:} Análise de padrões sensacionalistas nos títulos;
	\item \textbf{Meta-Classificador (Modelo Final):} Agregação das saídas anteriores para a previsão final de veracidade.
\end{itemize}

Nas subsecções seguintes, é descrito o ciclo de vida de desenvolvimento para cada um destes componentes, abrangendo desde o pré-processamento específico e engenharia de atributos (\textit{Feature Engineering}), até à justificação da escolha dos algoritmos.

% Para cada modelo devo falar dos algoritmos testados e a justificação da escolha
\subsection{Modelo 1: Classificação de Tópicos} \label{subsec:topic-classification}

Inicialmente, a abordagem explorada consistiu numa \textit{pipeline} simples de \textit{Clustering} baseada em TF-IDF (\textit{Term Frequency-Inverse Document Frequency}), seguindo o fluxo: \textit{Pré-processamento} $\rightarrow$ \textit{TF-IDF} $\rightarrow$ \textit{Clustering}. Contudo, rapidamente tornou-se evidente a necessidade de reduzir a dimensionalidade da matriz resultante da vetorização para obter resultados mais robustos.

Numa segunda iteração, optou-se pela utilização de \textit{Feature Hashing} (unsigned) como técnica de vetorização, devido à sua rapidez e otimização de memória em comparação com o TF-IDF tradicional. Para a redução de dimensionalidade, foram testadas e comparadas duas abordagens: LSA (\textit{Latent Semantic Analysis}) e NMF (\textit{Non-Negative Matrix Factorization}), resultando no fluxo: \textit{Pré-processamento} $\rightarrow$ \textit{Hashing} $\rightarrow$ \textit{NMF/LSA} $\rightarrow$ \textit{Clustering}.

A análise dos resultados desta segunda abordagem revelou uma segmentação ineficiente dos \textit{clusters}. Frequentemente, os algoritmos identificavam apenas dois grandes grupos: um "Tópico A" muito específico (como desporto ou política) e um "Tópico B" que englobava o resto dos dados. Além disso, verificou-se que a otimização baseada no \textit{Silhouette Score} não era ideal, visto ser uma métrica puramente geométrica que não captura necessariamente a coerência semântica dos tópicos gerados. A Tabela \ref{tab:topic-clustering-comparison} resume os resultados quantitativos obtidos nestas experiências, comparando as diferentes configurações testadas.


\begin{table}[h]
	\centering
	\small
	\renewcommand{\arraystretch}{1.2}
	\caption{Comparação das métricas de qualidade obtidas nas diferentes abordagens testadas para classificação de tópicos.}
	\label{tab:topic-clustering-comparison}
	\begin{tabular}{lllr}
		\toprule % Linha grossa no topo
		\textbf{Redução} & \textbf{Modelo} & \textbf{Métrica} & \textbf{Score} \\
		\midrule % Linha média separando o cabeçalho
		
		LSA & KMeans  & Silhouette & 0.3843 \\
		& HDBSCAN & Silhouette & 0.4490 \\
		& GMM     & Silhouette & 0.5504 \\
		
		\addlinespace 
		
		NMF & KMeans  & Silhouette & 0.5413 \\
		& HDBSCAN & Silhouette & 0.3772 \\
		& GMM     & Silhouette & \textbf{0.5536} \\
		
		\midrule % Separação final para a conclusão
		
		\multicolumn{2}{l}{\textit{Modelagem de Tópicos (Sem redução)}} & & \\
		--  & NMF (TF-IDF) & Coerência & \textbf{0.7279} \\
		\bottomrule % Linha grossa no final
	\end{tabular}
\end{table}

Consequentemente, a metodologia final evoluiu para o uso de NMF diretamente sobre TF-IDF como técnica de modelação de tópicos, em vez de apenas redução para clustering (\textit{Pré-processamento} $\rightarrow$ \textit{TF-IDF} $\rightarrow$ \textit{NMF}). A escolha do NMF justifica-se pela sua capacidade de criar "clusters probabilísticos", onde um documento não pertence apenas a um grupo de forma binária, mas possui um peso de pertença (ex: Tópico A: 0.9, Tópico B: 0.1), o que é mais representativo da realidade das notícias.

Para a avaliação e otimização final, substituiu-se o critério geométrico (\textit{Silhouette Score}) pelo \textit{Coherence Score}, uma métrica mais indicada para avaliar a qualidade semântica e a interpretabilidade humana dos tópicos extraídos. A distribuição final dos tópicos, resultante desta abordagem otimizada, pode ser visualizada na Figura \ref{fig:nmfclusters}.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{imagens/nmf_clusters}
	\caption{Visualização da distribuição dos tópicos obtidos com a abordagem final utilizando NMF.}
	\label{fig:nmfclusters}
\end{figure}

\subsection{Modelo 2: Análise de Anomalias} \label{subsec:anomaly-analysis}
Para a deteção de anomalias, assumiu-se que notícias falsas divergem estruturalmente das verdadeiras, comportando-se como \textit{outliers}. Utilizou-se o \textit{dataset} ISOT unificado (com coluna de classe adicionada), adotando-se uma estratégia de deteção de novidade com contaminação controlada: os modelos foram treinados maioritariamente com notícias verdadeiras, mas com uma contaminação de 5\% de dados falsos para aumentar a robustez a ruído.

Foram comparados dois algoritmos: \textit{Isolation Forest}, pela sua eficiência em isolar anomalias em alta dimensionalidade, e \textit{Dense Autoencoder}, pela capacidade de detetar erros de reconstrução em padrões não aprendidos. Como demonstra a Tabela \ref{tab:anomaly-results}, ambos obtiveram uma performance muito semelhante, com o \textit{Isolation Forest} a apresentar uma vantagem marginal no F1-Score, validando qualquer um dos modelos para a solução.

\begin{table}[h]
	\centering
	\small
	\renewcommand{\arraystretch}{1.2}
	\caption{Comparação do desempenho (F1-Score) entre os modelos de deteção de anomalias.}
	\label{tab:anomaly-results}
	\begin{tabular}{lc}
		\toprule % Linha grossa no topo
		\textbf{Modelo} & \textbf{F1-Score-Weighted} \\
		\midrule % Linha média separando o cabeçalho
		
		Isolation Forest & 0.9226 \\
		Dense Autoencoder & 0.9175 \\
		
		\bottomrule % Linha grossa no final
	\end{tabular}
\end{table}

A análise visual da dispersão (Figura \ref{fig:anomaly-scatter}) revela que ambos os modelos identificam mais anomalias do que a classificação original. No entanto, o \textit{Dense Autoencoder} demonstra um comportamento mais conservador do que o \textit{Isolation Forest}, apresentando uma densidade de pontos anómalos (vermelhos) visualmente mais próxima da distribuição real, sugerindo a existência de padrões latentes no texto que transcendem a rotulagem binária original.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{imagens/anomaly_scatterplot}
	\caption{Comparação visual da distribuição de anomalias: (Esquerda) Classificação real; (Centro) Predição Isolation Forest; (Direita) Predição Dense Autoencoder.}
	\label{fig:anomaly-scatter}
\end{figure}

\subsection{Modelo 3: Deteção de Stance (Postura)} \label{subsec:stance-detection}

\subsection{Modelo 4: Deteção de Clickbait} \label{subsec:clickbait-detection}

\subsection{Modelo Final: Fake News Meta-Classifier} \label{subsec:modelo-final}
% Como as saídas dos modelos anteriores (1, 2 e 3) entram neste modelo.
\section{Desenvolvimento dos Modelos (Metodologia)} \label{sec:desenvolvimento-modelos}
% Aqui descreves o "coração" do trabalho. Para cada sub-tópico abaixo, deves identificar e justificar os algoritmos e parâmetros.

O presente capítulo detalha a metodologia adotada para o desenvolvimento do sistema de deteção de \textit{Fake News}. Dada a natureza multidimensional da desinformação, optou-se por uma arquitetura modular hierárquica (abordagem inspirada em \textit{Stacking Ensemble}), em vez de um único modelo monolítico.

Para tal, foram desenvolvidos modelos especialistas independentes, treinados em \textit{datasets} distintos, cujo objetivo é capturar diferentes nuances linguísticas e estruturais das notícias. As saídas probabilísticas destes modelos funcionam como \textit{features} de alto nível (meta-features) para o classificador final.

A arquitetura proposta compreende os seguintes módulos:

\begin{itemize}
	\item \textbf{Classificação de Tópicos:} Contextualização temática do artigo (ex: Política, Saúde, Tecnologia);
	\item \textbf{Análise de Anomalias:} Identificação de padrões nos textuais em notícias verdadeiras de modo a detetar anomalias;
	\item \textbf{Deteção de Stance (Postura):} Análise da concordância entre o título e o corpo da notícia;
	\item \textbf{Deteção de Clickbait:} Análise de padrões sensacionalistas nos títulos;
	\item \textbf{Meta-Classificador (Modelo Final):} Agregação das saídas anteriores para a previsão final de veracidade.
\end{itemize}

Nas subsecções seguintes, é descrito o ciclo de vida de desenvolvimento para cada um destes componentes, abrangendo desde o pré-processamento específico e engenharia de atributos (\textit{Feature Engineering}), até à justificação da escolha dos algoritmos.

% Para cada modelo devo falar dos algoritmos testados e a justificação da escolha
\subsection{Modelo 1: Classificação de Tópicos} \label{subsec:topic-classification}

Inicialmente, a abordagem explorada consistiu numa \textit{pipeline} simples de \textit{Clustering} baseada em TF-IDF (\textit{Term Frequency-Inverse Document Frequency}), seguindo o fluxo: \textit{Pré-processamento} $\rightarrow$ \textit{TF-IDF} $\rightarrow$ \textit{Clustering}. Contudo, rapidamente tornou-se evidente a necessidade de reduzir a dimensionalidade da matriz resultante da vetorização para obter resultados mais robustos.

Numa segunda iteração, optou-se pela utilização de \textit{Feature Hashing} (unsigned) como técnica de vetorização, devido à sua rapidez e otimização de memória em comparação com o TF-IDF tradicional. Para a redução de dimensionalidade, foram testadas e comparadas duas abordagens: LSA (\textit{Latent Semantic Analysis}) e NMF (\textit{Non-Negative Matrix Factorization}), resultando no fluxo: \textit{Pré-processamento} $\rightarrow$ \textit{Hashing} $\rightarrow$ \textit{NMF/LSA} $\rightarrow$ \textit{Clustering}.

A análise dos resultados desta segunda abordagem revelou uma segmentação ineficiente dos \textit{clusters}. Frequentemente, os algoritmos identificavam apenas dois grandes grupos: um "Tópico A" muito específico (como desporto ou política) e um "Tópico B" que englobava o resto dos dados. Além disso, verificou-se que a otimização baseada no \textit{Silhouette Score} não era ideal, visto ser uma métrica puramente geométrica que não captura necessariamente a coerência semântica dos tópicos gerados. A Tabela \ref{tab:topic-clustering-comparison} resume os resultados quantitativos obtidos nestas experiências, comparando as diferentes configurações testadas.


\begin{table}[h]
	\centering
	\small
	\renewcommand{\arraystretch}{1.2}
	\caption{Comparação das métricas de qualidade obtidas nas diferentes abordagens testadas para classificação de tópicos.}
	\label{tab:topic-clustering-comparison}
	\begin{tabular}{lllr}
		\toprule % Linha grossa no topo
		\textbf{Redução} & \textbf{Modelo} & \textbf{Métrica} & \textbf{Score} \\
		\midrule % Linha média separando o cabeçalho
		
		LSA & KMeans  & Silhouette & 0.3843 \\
		& HDBSCAN & Silhouette & 0.4490 \\
		& GMM     & Silhouette & 0.5504 \\
		
		\addlinespace 
		
		NMF & KMeans  & Silhouette & 0.5413 \\
		& HDBSCAN & Silhouette & 0.3772 \\
		& GMM     & Silhouette & \textbf{0.5536} \\
		
		\midrule % Separação final para a conclusão
		
		\multicolumn{2}{l}{\textit{Modelagem de Tópicos (Sem redução)}} & & \\
		--  & NMF (TF-IDF) & Coerência & \textbf{0.7279} \\
		\bottomrule % Linha grossa no final
	\end{tabular}
\end{table}

Consequentemente, a metodologia final evoluiu para o uso de NMF diretamente sobre TF-IDF como técnica de modelação de tópicos, em vez de apenas redução para clustering (\textit{Pré-processamento} $\rightarrow$ \textit{TF-IDF} $\rightarrow$ \textit{NMF}). A escolha do NMF justifica-se pela sua capacidade de criar "clusters probabilísticos", onde um documento não pertence apenas a um grupo de forma binária, mas possui um peso de pertença (ex: Tópico A: 0.9, Tópico B: 0.1), o que é mais representativo da realidade das notícias.

Para a avaliação e otimização final, substituiu-se o critério geométrico (\textit{Silhouette Score}) pelo \textit{Coherence Score}, uma métrica mais indicada para avaliar a qualidade semântica e a interpretabilidade humana dos tópicos extraídos. A distribuição final dos tópicos, resultante desta abordagem otimizada, pode ser visualizada na Figura \ref{fig:nmfclusters}.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{imagens/nmf_clusters}
	\caption{Visualização da distribuição dos tópicos obtidos com a abordagem final utilizando NMF.}
	\label{fig:nmfclusters}
\end{figure}

\subsection{Modelo 2: Análise de Anomalias} \label{subsec:anomaly-analysis}
Para esta componente, formulou-se inicialmente a hipótese de que as notícias falsas constituiriam "anomalias" estatísticas, divergindo significativamente das notícias verdadeiras sem a necessidade de etiquetas explícitas (\textit{Unsupervised Learning}).

Numa primeira fase experimental, foram aplicados algoritmos de deteção de anomalias (incluindo \textit{Isolation Forest}, \textit{One-Class SVM} e \textit{Autoencoders}) no \textit{dataset} ISOT. Contudo, os resultados refutaram a hipótese inicial: as notícias falsas partilhavam demasiadas semelhanças estruturais e vocabulares com as verdadeiras, resultando numa incapacidade dos modelos em separar as classes (F1-Scores inferiores a 0.10). Concluiu-se que, neste contexto, as notícias desinformativas não são tão diferentes das verdadeiras.

Face a esta limitação, alterou-se a estratégia para uma abordagem de \textbf{Aprendizagem Supervisionada}. O problema foi reestruturado utilizando um \textit{dataset} equilibrado (50\% notícias reais, 50\% falsas), permitindo aos algoritmos aprenderem as características discriminatórias de cada classe. Foram treinados três modelos distintos: \textit{Random Forest}, \textit{Support Vector Machine} (SVM) e uma \textit{Neural Network}.

Ao contrário da tentativa não supervisionada, esta abordagem obteve resultados satisfatórios, conforme demonstrado na Tabela \ref{tab:supervised-results}.

\begin{table}[h]
	\centering
	\small
	\renewcommand{\arraystretch}{1.2}
	\caption{Comparação de desempenho (F1-Score) após a transição para Aprendizagem Supervisionada (Dataset Equilibrado).}
	\label{tab:supervised-results}
	\begin{tabular}{lc}
		\toprule
		\textbf{Modelo} & \textbf{F1-Score} \\
		\midrule
		Random Forest & 0.9720 \\
		SVM & 0.9774 \\
		Neural Network & \textbf{0.9896} \\
		\bottomrule
	\end{tabular}
\end{table}

A eficiência desta nova estratégia é demonstrada na Figura \ref{fig:supervised-scatter}. Enquanto a abordagem anterior apresentava uma sobreposição total, os novos modelos supervisionados conseguiram criar fronteiras de decisão claras, separando eficazmente as notícias verdadeiras das falsas.

\begin{figure}[h]
	\centering
	\includegraphics[width=1.0\linewidth]{imagens/supervised_scatterplot_results}
	\caption{Visualização dos resultados da abordagem supervisionada}
	\label{fig:supervised-scatter}
\end{figure}

Desta análise comparativa, selecionou-se a Rede Neuronal (F1: 0.9896) como o modelo final, por ter uma capacidade maior de generalização na distinção de padrões complexos em notícias.

\subsection{Modelo 3: Deteção de Stance (Postura)} \label{subsec:stance-detection}

O objetivo deste modelo é identificar a relação de concordância entre o título da notícia e o seu corpo, assumindo que notícias falsas apresentam frequentemente incoerências ou títulos "clickbait" que não correspondem ao conteúdo textual.

O principal desafio encontrado no desenvolvimento deste modelo foi o  desequilíbrio do \textit{dataset}. A classe maioritária ("unrelated" ou neutro) dominava as restantes, enviesando o modelo. Para mitigar este problema, aplicou-se uma técnica de \textit{undersampling}, reduzindo aleatoriamente o número de exemplos da classe dominante até se obter uma distribuição equilibrada entre as classes, permitindo ao modelo aprender padrões distintivos de todas as categorias.

Na fase de vetorização, optou-se por aumentar a complexidade da representação TF-IDF para capturar melhor o contexto semântico. O parâmetro \texttt{max\_features} foi aumentado para expandir o vocabulário considerado, e o intervalo de \textit{n-grams} foi configurado para $(1, 3)$. Isto significa que o modelo passou a analisar não apenas palavras isoladas (unigramas), mas também sequências de duas e três palavras (bigramas e trigramas), capturando expressões compostas essenciais para determinar a postura do texto.

Contrariamente aos módulos anteriores, não foi aplicada qualquer redução de dimensionalidade. As experiências realizadas demonstraram que a compressão do espaço vetorial resultava numa perda significativa de qualidade, indicando que a dispersão original dos dados era necessária para uma classificação eficaz. Dada a simplicidade e a alta dimensionalidade dos dados resultantes, comparou-se o desempenho de uma \textit{Support Vector Machine} (SVM) e de uma \textit{Random Forest}.

\begin{table}[h]
	\centering
	\small
	\renewcommand{\arraystretch}{1.2}
	\caption{Comparação do desempenho (F1-Score Macro) para a deteção de Stance.}
	\label{tab:stance-results}
	\begin{tabular}{lc}
		\toprule
		\textbf{Modelo} & \textbf{F1-Score (Macro)} \\
		\midrule
		SVM & \textbf{0.8464} \\
		Random Forest & 0.51 \\
		\bottomrule
	\end{tabular}
\end{table}

Os resultados, apresentados na Tabela \ref{tab:stance-results}, revelam uma grande diferença de desempenho. A SVM obteve um F1-Score de 0.8464, demonstrando uma capacidade muito superior para lidar com a alta dimensionalidade dos vetores de texto gerados pelos \textit{n-grams}, enquanto o \textit{Random Forest} revelou-se ineficaz para este nível de complexidade vetorial.

\subsection{Modelo 4: Deteção de Clickbait} \label{subsec:clickbait-detection}
A última componente foca-se na análise dos títulos das notícias, com o objetivo de identificar o uso de técnicas de sensacionalismo, exagero ou omissão deliberada de informação (\textit{clickbait}) para atrair a atenção do leitor.

O conjunto de dados utilizado para o treino foi o \textit{ClickbaitDataset}. Considerando a natureza deste problema (classificação binária baseada em títulos curtos) e a especificidade do vocabulário tipicamente utilizado neste tipo de chamadas, optou-se por não aplicar técnicas de redução de dimensionalidade. As experiências preliminares indicaram que a compressão do espaço vetorial tendia a eliminar nuances linguísticas e palavras-chave determinantes, não justificando o ganho computacional face à relativa simplicidade do \textit{dataset}.

Para esta tarefa de classificação, foram selecionadas e comparados dois algoritmos distintos: \textit{XGBoost} (\textit{Extreme Gradient Boosting}) e \textit{CNN} (\textit{Convolutional Neural Network}). O \textit{XGBoost} foi escolhido por ser robusto e eficiente, servindo como uma linha de base sólida baseada em árvores de decisão. Por outro lado, a \textit{CNN} foi selecionada por ser capaz de detetar padrões locais e sequenciais (como \textit{n-grams} ou expressões específicas bastante utilizadas por títulos sensacionalistas) independentemente da sua posição na frase, uma característica teórica vantajosa para análise de texto curto.

Os resultados quantitativos, apresentados na Tabela \ref{tab:clickbait-results}, validam a hipótese inicial sobre a superioridade das redes neuronais para este contexto específico.

\begin{table}[h]
	\centering
	\small
	\renewcommand{\arraystretch}{1.2}
	\caption{Comparação do desempenho (F1-Score Binary) para a deteção de Clickbait.}
	\label{tab:clickbait-results}
	\begin{tabular}{lc}
		\toprule
		\textbf{Modelo} & \textbf{F1-Score (Default - Binary)} \\
		\midrule
		XGBoost & 0.8462 \\
		CNN & \textbf{0.9509} \\ 
		\bottomrule
	\end{tabular}
\end{table}

A CNN apresentou um desempenho significativamente superior ao XGBoost (F1-Score de 0.9509 contra 0.8462). Este resultado demonstra que a deteção de \textit{clickbait} beneficia consideravelmente da extração de características espaciais e padrões locais que as camadas convolucionais conseguem isolar melhor, superando a abordagem de \textit{gradient boosting} na captura da estrutura sintática e semântica de títulos sensacionalistas.

\subsection{Modelo Final: Fake News Meta-Classifier} \label{subsec:modelo-final}
% Como as saídas dos modelos anteriores (1, 2 e 3) entram neste modelo.
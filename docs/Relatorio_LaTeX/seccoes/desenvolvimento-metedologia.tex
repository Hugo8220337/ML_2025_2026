\section{Desenvolvimento dos Modelos (Metodologia)} \label{sec:desenvolvimento-modelos}
% Aqui descreves o "coração" do trabalho. Para cada sub-tópico abaixo, deves identificar e justificar os algoritmos e parâmetros.

O presente capítulo detalha a metodologia adotada para o desenvolvimento do sistema de deteção de \textit{Fake News}. Dada a natureza multidimensional da desinformação, optou-se por uma arquitetura modular hierárquica (abordagem inspirada em \textit{Stacking Ensemble}), em vez de um único modelo monolítico.

Para tal, foram desenvolvidos modelos especialistas independentes, treinados em \textit{datasets} distintos, cujo objetivo é capturar diferentes nuances linguísticas e estruturais das notícias. As saídas probabilísticas destes modelos funcionam como \textit{features} de alto nível (meta-features) para o classificador final.

A arquitetura proposta compreende os seguintes módulos:

\begin{itemize}
	\item \textbf{Classificação de Tópicos:} Contextualização temática do artigo (ex: Política, Saúde, Tecnologia);
	\item \textbf{Análise de Anomalias:} Identificação de padrões nos textuais em notícias verdadeiras de modo a detetar anomalias;
	\item \textbf{Deteção de Stance (Postura):} Análise da concordância entre o título e o corpo da notícia;
	\item \textbf{Deteção de Clickbait:} Análise de padrões sensacionalistas nos títulos;
	\item \textbf{Meta-Classificador (Modelo Final):} Agregação das saídas anteriores para a previsão final de veracidade.
\end{itemize}

Nas subsecções seguintes, é descrito o ciclo de vida de desenvolvimento para cada um destes componentes, abrangendo desde o pré-processamento específico e engenharia de atributos (\textit{Feature Engineering}), até à justificação da escolha dos algoritmos.

% Para cada modelo devo falar dos algoritmos testados e a justificação da escolha
\subsection{Modelo 1: Classificação de Tópicos} \label{subsec:topic-classification}

Inicialmente, a abordagem explorada consistiu numa \textit{pipeline} simples de \textit{Clustering} baseada em TF-IDF (\textit{Term Frequency-Inverse Document Frequency}), seguindo o fluxo: \textit{Pré-processamento} $\rightarrow$ \textit{TF-IDF} $\rightarrow$ \textit{Clustering}. Contudo, rapidamente tornou-se evidente a necessidade de reduzir a dimensionalidade da matriz resultante da vetorização para obter resultados mais robustos.

Numa segunda iteração, optou-se pela utilização de \textit{Feature Hashing} (unsigned) como técnica de vetorização, devido à sua rapidez e otimização de memória em comparação com o TF-IDF tradicional. Para a redução de dimensionalidade, foram testadas e comparadas duas abordagens: LSA (\textit{Latent Semantic Analysis}) e NMF (\textit{Non-Negative Matrix Factorization}), resultando no fluxo: \textit{Pré-processamento} $\rightarrow$ \textit{Hashing} $\rightarrow$ \textit{NMF/LSA} $\rightarrow$ \textit{Clustering}.

A análise dos resultados desta segunda abordagem revelou uma segmentação ineficiente dos \textit{clusters}. Frequentemente, os algoritmos identificavam apenas dois grandes grupos: um "Tópico A" muito específico (como desporto ou política) e um "Tópico B" que englobava o resto dos dados. Além disso, verificou-se que a otimização baseada no \textit{Silhouette Score} não era ideal, visto ser uma métrica puramente geométrica que não captura necessariamente a coerência semântica dos tópicos gerados. A Tabela \ref{tab:topic-clustering-comparison} resume os resultados quantitativos obtidos nestas experiências, comparando as diferentes configurações testadas.


\begin{table}[h]
	\centering
	\small
	\renewcommand{\arraystretch}{1.2}
	\caption{Comparação das métricas de qualidade obtidas nas diferentes abordagens testadas para classificação de tópicos.}
	\label{tab:topic-clustering-comparison}
	\begin{tabular}{lllr}
		\toprule % Linha grossa no topo
		\textbf{Redução} & \textbf{Modelo} & \textbf{Métrica} & \textbf{Score} \\
		\midrule % Linha média separando o cabeçalho
		
		LSA & KMeans  & Silhouette & 0.3843 \\
		& HDBSCAN & Silhouette & 0.4490 \\
		& GMM     & Silhouette & 0.5504 \\
		
		\addlinespace 
		
		NMF & KMeans  & Silhouette & 0.5413 \\
		& HDBSCAN & Silhouette & 0.3772 \\
		& GMM     & Silhouette & \textbf{0.5536} \\
		
		\midrule % Separação final para a conclusão
		
		\multicolumn{2}{l}{\textit{Modelagem de Tópicos (Sem redução)}} & & \\
		--  & NMF (TF-IDF) & Coerência & \textbf{0.7279} \\
		\bottomrule % Linha grossa no final
	\end{tabular}
\end{table}

Consequentemente, a metodologia final evoluiu para o uso de NMF diretamente sobre TF-IDF como técnica de modelação de tópicos, em vez de apenas redução para clustering (\textit{Pré-processamento} $\rightarrow$ \textit{TF-IDF} $\rightarrow$ \textit{NMF}). A escolha do NMF justifica-se pela sua capacidade de criar "clusters probabilísticos", onde um documento não pertence apenas a um grupo de forma binária, mas possui um peso de pertença (ex: Tópico A: 0.9, Tópico B: 0.1), o que é mais representativo da realidade das notícias.

Para a avaliação e otimização final, substituiu-se o critério geométrico (\textit{Silhouette Score}) pelo \textit{Coherence Score}, uma métrica mais indicada para avaliar a qualidade semântica e a interpretabilidade humana dos tópicos extraídos. A distribuição final dos tópicos, resultante desta abordagem otimizada, pode ser visualizada na Figura \ref{fig:nmfclusters}.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{imagens/nmf_clusters}
	\caption{Visualização da distribuição dos tópicos obtidos com a abordagem final utilizando NMF.}
	\label{fig:nmfclusters}
\end{figure}

\subsection{Modelo 2: Análise de Anomalias} \label{subsec:anomaly-analysis}
Para a componente de deteção de anomalias, partiu-se da hipótese inicial de que as notícias falsas (\textit{fake news}) divergiriam linguística e estruturalmente das verdadeiras, podendo ser detetadas como \textit{outliers} sem necessidade de etiquetas explícitas (\textit{Unsupervised Learning}).

Para validar esta hipótese no \textit{dataset} ISOT, testaram-se quatro arquiteturas distintas: abordagem estatística (\textit{Isolation Forest}), geométrica (\textit{One-Class SVM}) e baseada em reconstrução (\textit{Dense Autoencoder} e \textit{Embedding Autoencoder}). Foram aplicadas técnicas de redução de dimensionalidade (LSA) para remoção de ruído e calibração da sensibilidade do modelo.

Contrariando a expectativa inicial, os resultados experimentais comprovaram que a abordagem não supervisionada é ineficaz para este conjunto de dados. Como demonstra a Tabela \ref{tab:anomaly-results}, todos os quatro modelos falharam em atingir um F1-Score (Binary) superior a 0.10. A análise dos erros revelou que os modelos sinalizavam consistentemente notícias verdadeiras como anomalias (Falsos Positivos) ou falhavam na deteção das falsas.

\begin{table}[h]
	\centering
	\small
	\renewcommand{\arraystretch}{1.2}
	\caption{Comparação do desempenho (F1-Score Binary) entre os modelos não supervisionados de deteção de anomalias.}
	\label{tab:anomaly-results}
	\begin{tabular}{lcccc}
		\toprule
		\textbf{Métrica} & \textbf{Isol. Forest} & \textbf{Dense AE} & \textbf{Embed. AE} & \textbf{OC-SVM} \\
		\midrule
		F1-Score (Binary) & 0.0417 & 0.0527 & 0.0769 & \textbf{0.0952} \\
		\bottomrule
	\end{tabular}
\end{table}

A análise visual da dispersão (Figura \ref{fig:anomaly-scatter}) confirma as métricas obtidas. Observa-se uma sobreposição significativa entre as distribuições das classes e as fronteiras de decisão dos modelos, evidenciando que o vocabulário e a estrutura das notícias falsas no ISOT são demasiado semelhantes às notícias reais para serem distinguidos por métodos puramente estatísticos ou de reconstrução.

\begin{figure}[h]
	\centering
	\includegraphics[width=1.0\linewidth]{imagens/anomaly_scatterplot}
	\caption{Visualização da incapacidade de separação das anomalias: Sobreposição entre a classificação real e as predições dos modelos não supervisionados.}
	\label{fig:anomaly-scatter}
\end{figure}

Esta falha experimental constitui um resultado relevante, pois prova que, neste contexto, a desinformação não é uma anomalia estatística detetável. Consequentemente, abandonou-se a via não supervisionada, alterando a estratégia para algoritmos de Aprendizagem Supervisionada (como \textit{Random Forest} e SVM), que demonstraram posteriormente capacidade de generalização ao aprender com as etiquetas explícitas das notícias.

\subsection{Modelo 3: Deteção de Stance (Postura)} \label{subsec:stance-detection}

O objetivo deste modelo é identificar a relação de concordância entre o título da notícia e o seu corpo, assumindo que notícias falsas apresentam frequentemente incoerências ou títulos "clickbait" que não correspondem ao conteúdo textual.

O principal desafio encontrado no desenvolvimento deste modelo foi o  desequilíbrio do \textit{dataset}. A classe maioritária ("unrelated" ou neutro) dominava as restantes, enviesando o modelo. Para mitigar este problema, aplicou-se uma técnica de \textit{undersampling}, reduzindo aleatoriamente o número de exemplos da classe dominante até se obter uma distribuição equilibrada entre as classes, permitindo ao modelo aprender padrões distintivos de todas as categorias.

Na fase de vetorização, optou-se por aumentar a complexidade da representação TF-IDF para capturar melhor o contexto semântico. O parâmetro \texttt{max\_features} foi aumentado para expandir o vocabulário considerado, e o intervalo de \textit{n-grams} foi configurado para $(1, 3)$. Isto significa que o modelo passou a analisar não apenas palavras isoladas (unigramas), mas também sequências de duas e três palavras (bigramas e trigramas), capturando expressões compostas essenciais para determinar a postura do texto.

Contrariamente aos módulos anteriores, não foi aplicada qualquer redução de dimensionalidade. As experiências realizadas demonstraram que a compressão do espaço vetorial resultava numa perda significativa de qualidade, indicando que a dispersão original dos dados era necessária para uma classificação eficaz. Dada a simplicidade e a alta dimensionalidade dos dados resultantes, comparou-se o desempenho de uma \textit{Support Vector Machine} (SVM) e de uma \textit{Random Forest}.

\begin{table}[h]
	\centering
	\small
	\renewcommand{\arraystretch}{1.2}
	\caption{Comparação do desempenho (F1-Score Macro) para a deteção de Stance.}
	\label{tab:stance-results}
	\begin{tabular}{lc}
		\toprule
		\textbf{Modelo} & \textbf{F1-Score (Macro)} \\
		\midrule
		SVM & \textbf{0.8464} \\
		Random Forest & 0.51 \\
		\bottomrule
	\end{tabular}
\end{table}

Os resultados, apresentados na Tabela \ref{tab:stance-results}, revelam uma grande diferença de desempenho. A SVM obteve um F1-Score de 0.8464, demonstrando uma capacidade muito superior para lidar com a alta dimensionalidade dos vetores de texto gerados pelos \textit{n-grams}, enquanto o \textit{Random Forest} revelou-se ineficaz para este nível de complexidade vetorial.

\subsection{Modelo 4: Deteção de Clickbait} \label{subsec:clickbait-detection}
A última componente foca-se na análise dos títulos das notícias, com o objetivo de identificar o uso de técnicas de sensacionalismo, exagero ou omissão deliberada de informação (\textit{clickbait}) para atrair a atenção do leitor.

O conjunto de dados utilizado para o treino foi o \textit{ClickbaitDataset}. Considerando a natureza deste problema (classificação binária baseada em títulos curtos) e a especificidade do vocabulário tipicamente utilizado neste tipo de chamadas, optou-se por não aplicar técnicas de redução de dimensionalidade. As experiências preliminares indicaram que a compressão do espaço vetorial tendia a eliminar nuances linguísticas e palavras-chave determinantes, não justificando o ganho computacional face à relativa simplicidade do \textit{dataset}.

Para esta tarefa de classificação, foram selecionadas e comparados dois algoritmos distintos: \textit{XGBoost} (\textit{Extreme Gradient Boosting}) e \textit{CNN} (\textit{Convolutional Neural Network}). O \textit{XGBoost} foi escolhido por ser robusto e eficiente, servindo como uma linha de base sólida baseada em árvores de decisão. Por outro lado, a \textit{CNN} foi selecionada por ser capaz de detetar padrões locais e sequenciais (como \textit{n-grams} ou expressões específicas bastante utilizadas por títulos sensacionalistas) independentemente da sua posição na frase, uma característica teórica vantajosa para análise de texto curto.

Os resultados quantitativos, apresentados na Tabela \ref{tab:clickbait-results}, validam a hipótese inicial sobre a superioridade das redes neuronais para este contexto específico.

\begin{table}[h]
	\centering
	\small
	\renewcommand{\arraystretch}{1.2}
	\caption{Comparação do desempenho (F1-Score Binary) para a deteção de Clickbait.}
	\label{tab:clickbait-results}
	\begin{tabular}{lc}
		\toprule
		\textbf{Modelo} & \textbf{F1-Score (Default - Binary)} \\
		\midrule
		XGBoost & 0.8462 \\
		CNN & \textbf{0.9509} \\ 
		\bottomrule
	\end{tabular}
\end{table}

A CNN apresentou um desempenho significativamente superior ao XGBoost (F1-Score de 0.9509 contra 0.8462). Este resultado demonstra que a deteção de \textit{clickbait} beneficia consideravelmente da extração de características espaciais e padrões locais que as camadas convolucionais conseguem isolar melhor, superando a abordagem de \textit{gradient boosting} na captura da estrutura sintática e semântica de títulos sensacionalistas.

\subsection{Modelo Final: Fake News Meta-Classifier} \label{subsec:modelo-final}
% Como as saídas dos modelos anteriores (1, 2 e 3) entram neste modelo.